{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8e_BQA70TeX"
      },
      "outputs": [],
      "source": [
        "!!pip install -q MOABB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkJNdnQ_xFOm"
      },
      "outputs": [],
      "source": [
        "!pip install pywd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa8aIBBvVyOl"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ssYTw8Yy-B9W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.signal\n",
        "import scipy.io as sio\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "import mne\n",
        "from pywt import wavedec \n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
        "import mlflow\n",
        "import mlflow.sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w7orvxzmBVsf"
      },
      "outputs": [],
      "source": [
        "import moabb\n",
        "from moabb.datasets import EPFLP300, utils\n",
        "from moabb.evaluations import CrossSessionEvaluation\n",
        "from moabb.paradigms import LeftRightImagery\n",
        "from moabb.pipelines.features import LogVariance\n",
        "from mne.filter import construct_iir_filter\n",
        "moabb.set_log_level(\"info\")\n",
        "\n",
        "\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_oqRjDT1Fhow"
      },
      "outputs": [],
      "source": [
        "dataset=EPFLP300()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_m3sM_PmJpBn"
      },
      "outputs": [],
      "source": [
        "def getData(subjectNumbers,dataset=EPFLP300()):\n",
        "  return dataset.get_data(subjectNumbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "khYPS4GnMkmX"
      },
      "outputs": [],
      "source": [
        "def getSubjectData(subjectNumber,session_number,run_number):\n",
        "  session = f'session_{session_number}'\n",
        "  run = f'run_{run_number}'\n",
        "  return getData([subjectNumber])[subjectNumber][session][run]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "w15NgQdUxioU"
      },
      "outputs": [],
      "source": [
        "def filterAndResampleData(data,seglen,lp=20,hp=0.1,sf=2048,resample=64):\n",
        "  iir_params = dict(order=6, ftype='butter', output='sos')  \n",
        "  iir_params = construct_iir_filter(iir_params, [hp,lp], None, sf, 'bandpass', return_copy=False)\n",
        "  data.filter(method='iir',iir_params=iir_params,h_freq=hp,l_freq=lp)\n",
        "  return data.resample(math.ceil(((sf*64)/seglen)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "QAg6VBp9UOFY"
      },
      "outputs": [],
      "source": [
        "def getTargetData(df):\n",
        "  Target = df[df['STI']==2].index.values\n",
        "  val = np.full(len(Target),2)\n",
        "  targetDF= pd.DataFrame(Target)\n",
        "  targetDF[\"value\"]=val\n",
        "  return targetDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "FmoKfDbJUUcb"
      },
      "outputs": [],
      "source": [
        "def getNonTargetData(df):\n",
        "  nonTarget = df[df['STI']==1].index.values\n",
        "  value = np.full(len(nonTarget),1)\n",
        "  nontargetDF= pd.DataFrame(nonTarget)\n",
        "  nontargetDF[\"value\"]=value\n",
        "  return nontargetDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "jMOrFXhKUXbM"
      },
      "outputs": [],
      "source": [
        "def getTottalData(df):\n",
        "  targetDF = getTargetData(df)\n",
        "  nontargetDF = getNonTargetData(df)\n",
        "  totaldf = nontargetDF.append(targetDF,ignore_index=True) \n",
        "  TargetNnonTarget = totaldf.sort_values(by=[0],ignore_index=True)\n",
        "  return TargetNnonTarget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "NdqdmOTdQCfW"
      },
      "outputs": [],
      "source": [
        "def scaleAndExtractFeatures(segment):\n",
        "  scaler = MinMaxScaler(feature_range = (-1,1))\n",
        "  df = segment.to_data_frame()\n",
        "  columns = ['time', 'MA1', 'MA2' , 'STI']\n",
        "  df.drop(columns,axis=1,inplace=True)\n",
        "  featureVector = []\n",
        "  for val in df.columns.values:\n",
        "    vals=df[val].values.reshape(-1, 1)\n",
        "    scaled = scaler.fit_transform(vals)\n",
        "    # print(\"rum number: \",runNum,\"\\nsegment number\",segindx)\n",
        "    col= scaled.reshape(64,)\n",
        "    cA2, cD2, cD1 = wavedec(col,'db4',level=2)\n",
        "    featureVector.extend(cA2)\n",
        "    featureVector.extend(cD2)\n",
        "    featureVector.extend(cD1)\n",
        "  return featureVector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "BI33qDkKRmSk"
      },
      "outputs": [],
      "source": [
        "def divideSingleRun(df, data):\n",
        "  TargetNnonTarget= getTottalData(df)\n",
        "  segments=[]\n",
        "  output=[]\n",
        "  length=len(TargetNnonTarget)\n",
        "  for index, row in TargetNnonTarget.iterrows():\n",
        "    if(index==length-1):\n",
        "      Segment = df.iloc[TargetNnonTarget[0].iloc[index]:]\n",
        "    else:\n",
        "      Segment = df.iloc[TargetNnonTarget[0].iloc[index]:TargetNnonTarget[0].iloc[index]+2048]\n",
        "\n",
        "    # crop segment from RawArray\n",
        "    d = data.copy()\n",
        "    Segment.reset_index(inplace=True)\n",
        "    tmax= Segment['time'][len(Segment)-1]\n",
        "    tmin= Segment['time'][0]\n",
        "    seg=d.crop(tmin=tmin, tmax=tmax)\n",
        "\n",
        "    # Filter and resample\n",
        "    filtered = filterAndResampleData(seg,len(Segment))\n",
        "\n",
        "    # Scale and extract features\n",
        "    if(len(filtered.to_data_frame())!=64):\n",
        "      continue\n",
        "    featureVector= scaleAndExtractFeatures(filtered)\n",
        "\n",
        "    segments.append(featureVector)\n",
        "    output.append(TargetNnonTarget['value'].iloc[index])\n",
        "  return segments, output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extractData(subjectNumber):\n",
        "  rawDataTrain=[]\n",
        "  rawDataTest=[]\n",
        "  for sessionNumber in range(1,4):\n",
        "    for runNumber in range(1,7):\n",
        "      data = getSubjectData(subjectNumber,sessionNumber,runNumber)\n",
        "      rawDataTrain.append(data)\n",
        "  for runNumber in range(1,7):\n",
        "    d= getSubjectData(subjectNumber,4,runNumber)\n",
        "    rawDataTest.append(d)\n",
        "  return rawDataTrain,rawDataTest"
      ],
      "metadata": {
        "id": "8Bkdc7Ej2E3w"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rawTrain, rawTest =extractData(1)"
      ],
      "metadata": {
        "id": "nZxAvZhM4pwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "RwKcbqtLguzS"
      },
      "outputs": [],
      "source": [
        "def Preprocess(rawTrain, rawTest):\n",
        "  x_train=[]\n",
        "  y_train=[]\n",
        "  for indx in range(18):\n",
        "    df = rawTrain[indx].to_data_frame()\n",
        "    segments, target = divideSingleRun(df, rawTrain[indx])\n",
        "    x_train+=segments\n",
        "    y_train+=target\n",
        "  x_test =[]\n",
        "  y_test =[]\n",
        "  for indx in range(6):\n",
        "      df=rawTest[indx].to_data_frame()\n",
        "      segments, target = divideSingleRun(df, rawTest[indx])\n",
        "      x_test+=segments\n",
        "      y_test+=target\n",
        "  return x_train,y_train, x_test ,y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "jkvVoMYtrM4i"
      },
      "outputs": [],
      "source": [
        "x_train,y_train, x_test ,y_test=Preprocess(rawTrain, rawTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "xD31tMg5jGjZ"
      },
      "outputs": [],
      "source": [
        "def SVM(subjectNumber,x_train,y_train, x_test ,y_test):\n",
        "  print(\"preparing Subject \",subjectNumber , \" Data.......\")\n",
        "  clf = svm.SVC()\n",
        "  clf.fit(x_train,y_train)\n",
        "  predictions =clf.predict(x_test)\n",
        "  print(subjectNumber , \"accuracy score \" , accuracy_score(predictions , y_test))\n",
        "  \n",
        "  cm = confusion_matrix(y_test,predictions,labels=[2,1])\n",
        "  print(cm)\n",
        "  print(\"______________________________________________\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This result with filtering to (0.1, 20) and with resampling to 64"
      ],
      "metadata": {
        "id": "v44zLckaFrFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVM(1,x_train,y_train, x_test ,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYgT_Y1kF8jR",
        "outputId": "cdadad07-dcdd-4375-ce11-625e074ae868"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preparing Subject  1  Data.......\n",
            "1 accuracy score  0.8611449451887941\n",
            "[[ 26 110]\n",
            " [  4 681]]\n",
            "______________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xTbgYkoGCJ7C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}